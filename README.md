# SuperInterview ‚Äî Simulateur d'entretien vocal par IA

> **Test Technique Lead Dev IA ‚Äì ProcessIQ**  
> Pipeline complet **STT ‚Üí LLM ‚Üí TTS** en temps r√©el, con√ßu pour minimiser la latence per√ßue.

---

##  Demo

```
Parole utilisateur ‚Üí Web Speech API (STT) ‚Üí Groq/Llama 3.3-70B (LLM streaming) ‚Üí Web Speech Synthesis (TTS)
```

---

## ‚öôÔ∏è Stack & Choix Technologiques

### STT ‚Äî Web Speech API (navigateur natif)
**Pourquoi pas Whisper ou Deepgram ?**

| Crit√®re | Web Speech API | Whisper/Deepgram |
|---|---|---|
| Latence | **0 ms** (local) | 300‚Äì800 ms (r√©seau) |
| Co√ªt | Gratuit | Payant |
| R√©sultats interims | ‚úÖ Oui | ‚ùå Non (ou WebSocket custom) |
| Pr√©cision FR | Bonne (Chrome) | Excellente |

La Web Speech API tourne enti√®rement dans le navigateur. Pas de round-trip r√©seau pour la transcription ‚Üí latence quasi-nulle. Les **r√©sultats interims** permettent d'afficher le transcript en temps r√©el pendant que l'utilisateur parle.

**D√©tection de silence automatique** : un `setTimeout` de 2s se r√©initialise √† chaque token de parole re√ßu. √Ä expiration, la r√©ponse est soumise automatiquement ‚Äî sans aucune intervention utilisateur. Le bouton manuel reste disponible en secours.

> **Limitation connue** : non support√© sur Firefox. Chrome et Edge uniquement.

---

### LLM ‚Äî Llama 3.3-70B via Groq
**Pourquoi Groq plut√¥t qu'OpenAI ou Gemini ?**

Groq utilise des **LPU** (Language Processing Units) au lieu de GPU, ce qui donne des vitesses de g√©n√©ration de **300‚Äì500 tokens/seconde** ‚Äî soit 5‚Äì10√ó plus rapide qu'OpenAI GPT-4.

| Crit√®re | Groq (Llama 3.3-70B) | OpenAI GPT-4o | Gemini Flash |
|---|---|---|---|
| Vitesse tokens/s | **~400** | ~80 | ~150 |
| Co√ªt | **Gratuit** (tier free) | ~$5/1M tokens | ~$0.10/1M |
| Qualit√© FR | Tr√®s bonne | Excellente | Bonne |
| Streaming SSE | ‚úÖ | ‚úÖ | ‚úÖ |

L'API Groq est **compatible OpenAI** ‚Äî drop-in replacement sans SDK sp√©cial, juste un `fetch` vers `api.groq.com`.

**Streaming token par token** : la r√©ponse est affich√©e et envoy√©e au TTS au fur et √† mesure (`enqueue`), sans attendre la fin de la g√©n√©ration.

---

### TTS ‚Äî Web Speech Synthesis API (navigateur natif)
**Pourquoi pas ElevenLabs ou Azure TTS ?**

M√™me logique que pour le STT : z√©ro latence r√©seau. La synth√®se commence **d√®s que le dernier token arrive** (`flush` apr√®s `[DONE]`).

Le texte est nettoy√© avant synth√®se (suppression du markdown que Llama peut √©mettre : `**bold**`, `*italic*`, `` `code` ``, `### heading`).

> Pour une v2 production : ElevenLabs ou Azure Neural TTS pour une voix plus naturelle, avec streaming audio WebSocket pour maintenir la faible latence.

---

##  Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Browser (Next.js)                      ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  useSTT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ
‚îÇ  (Web Speech API)   transcript                            ‚îÇ
‚îÇ       ‚îÇ                                                   ‚îÇ
‚îÇ       ‚ñº                                                   ‚îÇ
‚îÇ  VoiceInterview.tsx                                       ‚îÇ
‚îÇ  (state machine: idle ‚Üí listening ‚Üí thinking ‚Üí speaking)  ‚îÇ
‚îÇ       ‚îÇ                                                   ‚îÇ
‚îÇ       ‚ñº fetch SSE                                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                  Next.js API Route                        ‚îÇ
‚îÇ  /api/chat ‚îÄ‚îÄ‚ñ∫ Groq API (Llama 3.3-70B, streaming)       ‚îÇ
‚îÇ                token by token ‚Üí SSE ‚Üí browser             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                    Browser                                ‚îÇ
‚îÇ  useTTS ‚óÑ‚îÄ‚îÄ‚îÄ tokens (enqueue) ‚îÄ‚îÄ‚îÄ flush on [DONE]        ‚îÇ
‚îÇ  (Web Speech Synthesis API)                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Structure du projet

```
.
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ page.tsx                  # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx
‚îÇ   ‚îú‚îÄ‚îÄ globals.css               # CSS variables (th√®me dark)
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îî‚îÄ‚îÄ chat/
‚îÇ           ‚îî‚îÄ‚îÄ route.ts          # POST /api/chat ‚Äî SSE stream Groq
‚îÇ
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ VoiceInterview.tsx        # Composant principal (state machine)
‚îÇ   ‚îú‚îÄ‚îÄ MessageBubble.tsx         # Bulle de message user/IA
‚îÇ   ‚îú‚îÄ‚îÄ Waveform.tsx              # Animation audio pendant TTS
‚îÇ   ‚îî‚îÄ‚îÄ StatusBar.tsx             # Indicateur de phase
‚îÇ
‚îî‚îÄ‚îÄ lib/
    ‚îú‚îÄ‚îÄ useSTT.ts                 # Hook STT + d√©tection silence 2s
    ‚îî‚îÄ‚îÄ useTTS.ts                 # Hook TTS + buffer/flush streaming
```

---

##  Installation & Lancement

### Pr√©requis
- Node.js 18+
- Cl√© API Groq gratuite : [console.groq.com](https://console.groq.com)

### Setup

```bash
# 1. Cloner le repo
git clone https://github.com/ton-username/superinterview.git
cd superinterview

# 2. Installer les d√©pendances
npm install

# 3. Configurer la cl√© API
cp .env.example .env.local
# √âditer .env.local et renseigner GROQ_API_KEY=gsk_...

# 4. Lancer en d√©veloppement
npm run dev
```

Ouvrir [http://localhost:3000](http://localhost:3000) dans **Chrome** ou **Edge**.
Vid√©o d√©mo : https://drive.google.com/file/d/1tjOkkVGhsLBgKbbWN0UsJUgI3pprGgLu/view?usp=drive_link

### Variables d'environnement

```bash
# .env.local
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxx
```

> La cl√© n'est jamais expos√©e c√¥t√© client. Elle est utilis√©e uniquement dans l'API Route Next.js c√¥t√© serveur.

---

##  Gestion de la latence ‚Äî D√©cisions cl√©s

### 1. Silence Detection c√¥t√© client
Plut√¥t que d'attendre un bouton, un timer de **2 secondes** se r√©initialise √† chaque token de parole. Cela √©vite un round-trip "appuyer sur envoyer" et maintient une conversation naturelle.

### 2. Streaming SSE bout en bout
Le LLM envoie les tokens un par un via **Server-Sent Events**. Le composant React affiche chaque token imm√©diatement, et le TTS commence √† parler **sans attendre la fin de la r√©ponse compl√®te**.

### 3. Pas de r√©seau pour STT/TTS
Les deux √©tapes les plus fr√©quentes (√©coute et parole) fonctionnent **hors ligne** dans le navigateur. Seul le LLM n√©cessite un appel r√©seau.

### 4. `max_tokens: 300` sur le LLM
Le system prompt impose des r√©ponses courtes (2‚Äì4 phrases). Moins de tokens = fin de g√©n√©ration plus rapide = TTS d√©marre plus t√¥t.

### 5. Machine d'√©tat explicite
```
idle ‚Üí listening ‚Üí thinking ‚Üí speaking ‚Üí idle
```
Chaque transition est claire. Les boutons sont d√©sactiv√©s pendant `thinking` et tant que `tts.isSpeaking === true` pour √©viter les soumissions parasites.

---

## üîí S√©curit√©

- La cl√© API Groq est stock√©e **uniquement** dans `.env.local` (c√¥t√© serveur)
- Aucune cl√© n'est jamais envoy√©e au navigateur
- L'API Route Next.js fait office de proxy s√©curis√©

---

##  Am√©liorations V2

- **STT** : Remplacer Web Speech API par Whisper via WebSocket pour une meilleure pr√©cision multilingue
- **TTS** : ElevenLabs ou Azure Neural TTS pour une voix plus naturelle
- **LLM** : Prompt configurable selon le poste vis√©
- **Auth** : Prot√©ger l'API Route avec un token utilisateur
- **Analytics** : Dur√©e d'entretien, nombre d'√©changes, score automatique

---

##  D√©pendances principales

| Package | Version | R√¥le |
|---|---|---|
| `next` | 16.1.6 | Framework React fullstack |
| `react` | 19.2.3 | UI |
| `typescript` | ^5 | Typage statique |

**Aucune d√©pendance externe pour STT/TTS** ‚Äî Web APIs natives du navigateur.  
**Aucun SDK Groq** ‚Äî l'API est compatible OpenAI, un simple `fetch` suffit.

---
