# SuperInterview â€” Simulateur d'entretien vocal par IA

> **Test Technique Lead Dev IA â€“ ProcessIQ**  
> Pipeline complet **STT â†’ LLM â†’ TTS** en temps rÃ©el, conÃ§u pour minimiser la latence perÃ§ue.

---

##  Demo

```
Parole utilisateur â†’ Web Speech API (STT) â†’ Groq/Llama 3.3-70B (LLM streaming) â†’ Web Speech Synthesis (TTS)
```

---

## âš™ï¸ Stack & Choix Technologiques

### STT â€” Web Speech API (navigateur natif)
**Pourquoi pas Whisper ou Deepgram ?**

| CritÃ¨re | Web Speech API | Whisper/Deepgram |
|---|---|---|
| Latence | **0 ms** (local) | 300â€“800 ms (rÃ©seau) |
| CoÃ»t | Gratuit | Payant |
| RÃ©sultats interims | âœ… Oui | âŒ Non (ou WebSocket custom) |
| PrÃ©cision FR | Bonne (Chrome) | Excellente |

La Web Speech API tourne entiÃ¨rement dans le navigateur. Pas de round-trip rÃ©seau pour la transcription â†’ latence quasi-nulle. Les **rÃ©sultats interims** permettent d'afficher le transcript en temps rÃ©el pendant que l'utilisateur parle.

**DÃ©tection de silence automatique** : un `setTimeout` de 2s se rÃ©initialise Ã  chaque token de parole reÃ§u. Ã€ expiration, la rÃ©ponse est soumise automatiquement â€” sans aucune intervention utilisateur. Le bouton manuel reste disponible en secours.

> **Limitation connue** : non supportÃ© sur Firefox. Chrome et Edge uniquement.

---

### LLM â€” Llama 3.3-70B via Groq
**Pourquoi Groq plutÃ´t qu'OpenAI ou Gemini ?**

Groq utilise des **LPU** (Language Processing Units) au lieu de GPU, ce qui donne des vitesses de gÃ©nÃ©ration de **300â€“500 tokens/seconde** â€” soit 5â€“10Ã— plus rapide qu'OpenAI GPT-4.

| CritÃ¨re | Groq (Llama 3.3-70B) | OpenAI GPT-4o | Gemini Flash |
|---|---|---|---|
| Vitesse tokens/s | **~400** | ~80 | ~150 |
| CoÃ»t | **Gratuit** (tier free) | ~$5/1M tokens | ~$0.10/1M |
| QualitÃ© FR | TrÃ¨s bonne | Excellente | Bonne |
| Streaming SSE | âœ… | âœ… | âœ… |

L'API Groq est **compatible OpenAI** â€” drop-in replacement sans SDK spÃ©cial, juste un `fetch` vers `api.groq.com`.

**Streaming token par token** : la rÃ©ponse est affichÃ©e et envoyÃ©e au TTS au fur et Ã  mesure (`enqueue`), sans attendre la fin de la gÃ©nÃ©ration.

---

### TTS â€” Web Speech Synthesis API (navigateur natif)
**Pourquoi pas ElevenLabs ou Azure TTS ?**

MÃªme logique que pour le STT : zÃ©ro latence rÃ©seau. La synthÃ¨se commence **dÃ¨s que le dernier token arrive** (`flush` aprÃ¨s `[DONE]`).

Le texte est nettoyÃ© avant synthÃ¨se (suppression du markdown que Llama peut Ã©mettre : `**bold**`, `*italic*`, `` `code` ``, `### heading`).

> Pour une v2 production : ElevenLabs ou Azure Neural TTS pour une voix plus naturelle, avec streaming audio WebSocket pour maintenir la faible latence.

---

##  Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Browser (Next.js)                      â”‚
â”‚                                                           â”‚
â”‚  useSTT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  â”‚
â”‚  (Web Speech API)   transcript                            â”‚
â”‚       â”‚                                                   â”‚
â”‚       â–¼                                                   â”‚
â”‚  VoiceInterview.tsx                                       â”‚
â”‚  (state machine: idle â†’ listening â†’ thinking â†’ speaking)  â”‚
â”‚       â”‚                                                   â”‚
â”‚       â–¼ fetch SSE                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                  Next.js API Route                        â”‚
â”‚  /api/chat â”€â”€â–º Groq API (Llama 3.3-70B, streaming)       â”‚
â”‚                token by token â†’ SSE â†’ browser             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Browser                                â”‚
â”‚  useTTS â—„â”€â”€â”€ tokens (enqueue) â”€â”€â”€ flush on [DONE]        â”‚
â”‚  (Web Speech Synthesis API)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Structure du projet

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx                  # Entry point
â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”œâ”€â”€ globals.css               # CSS variables (thÃ¨me dark)
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ chat/
â”‚           â””â”€â”€ route.ts          # POST /api/chat â€” SSE stream Groq
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ VoiceInterview.tsx        # Composant principal (state machine)
â”‚   â”œâ”€â”€ MessageBubble.tsx         # Bulle de message user/IA
â”‚   â”œâ”€â”€ Waveform.tsx              # Animation audio pendant TTS
â”‚   â””â”€â”€ StatusBar.tsx             # Indicateur de phase
â”‚
â””â”€â”€ lib/
    â”œâ”€â”€ useSTT.ts                 # Hook STT + dÃ©tection silence 2s
    â””â”€â”€ useTTS.ts                 # Hook TTS + buffer/flush streaming
```

---

##  Installation & Lancement

### PrÃ©requis
- Node.js 18+
- ClÃ© API Groq gratuite : [console.groq.com](https://console.groq.com)

### Setup

```bash
# 1. Cloner le repo
git clone https://github.com/ton-username/superinterview.git
cd superinterview

# 2. Installer les dÃ©pendances
npm install

# 3. Configurer la clÃ© API
cp .env.example .env.local
# Ã‰diter .env.local et renseigner GROQ_API_KEY=gsk_...

# 4. Lancer en dÃ©veloppement
npm run dev
```

Ouvrir [http://localhost:3000](http://localhost:3000) dans **Chrome** ou **Edge**.
ğŸ¥ VidÃ©o dÃ©mo : https://drive.google.com/file/d/1tjOkkVGhsLBgKbbWN0UsJUgI3pprGgLu/view?usp=drive_link

### Variables d'environnement

```bash
# .env.local
GROQ_API_KEY=gsk_xxxxxxxxxxxxxxxxxxxx
```

> La clÃ© n'est jamais exposÃ©e cÃ´tÃ© client. Elle est utilisÃ©e uniquement dans l'API Route Next.js cÃ´tÃ© serveur.

---

##  Gestion de la latence â€” DÃ©cisions clÃ©s

### 1. Silence Detection cÃ´tÃ© client
PlutÃ´t que d'attendre un bouton, un timer de **2 secondes** se rÃ©initialise Ã  chaque token de parole. Cela Ã©vite un round-trip "appuyer sur envoyer" et maintient une conversation naturelle.

### 2. Streaming SSE bout en bout
Le LLM envoie les tokens un par un via **Server-Sent Events**. Le composant React affiche chaque token immÃ©diatement, et le TTS commence Ã  parler **sans attendre la fin de la rÃ©ponse complÃ¨te**.

### 3. Pas de rÃ©seau pour STT/TTS
Les deux Ã©tapes les plus frÃ©quentes (Ã©coute et parole) fonctionnent **hors ligne** dans le navigateur. Seul le LLM nÃ©cessite un appel rÃ©seau.

### 4. `max_tokens: 300` sur le LLM
Le system prompt impose des rÃ©ponses courtes (2â€“4 phrases). Moins de tokens = fin de gÃ©nÃ©ration plus rapide = TTS dÃ©marre plus tÃ´t.

### 5. Machine d'Ã©tat explicite
```
idle â†’ listening â†’ thinking â†’ speaking â†’ idle
```
Chaque transition est claire. Les boutons sont dÃ©sactivÃ©s pendant `thinking` et tant que `tts.isSpeaking === true` pour Ã©viter les soumissions parasites.

---

## ğŸ”’ SÃ©curitÃ©

- La clÃ© API Groq est stockÃ©e **uniquement** dans `.env.local` (cÃ´tÃ© serveur)
- Aucune clÃ© n'est jamais envoyÃ©e au navigateur
- L'API Route Next.js fait office de proxy sÃ©curisÃ©

---

## ğŸ›£ï¸ AmÃ©liorations V2

- **STT** : Remplacer Web Speech API par Whisper via WebSocket pour une meilleure prÃ©cision multilingue
- **TTS** : ElevenLabs ou Azure Neural TTS pour une voix plus naturelle
- **LLM** : Prompt configurable selon le poste visÃ©
- **Auth** : ProtÃ©ger l'API Route avec un token utilisateur
- **Analytics** : DurÃ©e d'entretien, nombre d'Ã©changes, score automatique

---

## ğŸ“¦ DÃ©pendances principales

| Package | Version | RÃ´le |
|---|---|---|
| `next` | 16.1.6 | Framework React fullstack |
| `react` | 19.2.3 | UI |
| `typescript` | ^5 | Typage statique |

**Aucune dÃ©pendance externe pour STT/TTS** â€” Web APIs natives du navigateur.  
**Aucun SDK Groq** â€” l'API est compatible OpenAI, un simple `fetch` suffit.

---

## ğŸ‘¤ Auteur

DÃ©veloppÃ© dans le cadre du test technique **Lead Dev IA â€“ ProcessIQ**  
DÃ©lai : 24h | Stack : Next.js 16 Â· React 19 Â· TypeScript Â· Groq Â· Web Speech API
